{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import model_selection, svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly partition the data and convert it to Count, Boolean, and TF-IDF Formats.\n",
    "# PCA has been removed due to its rather intense computational constraints. :(\n",
    "# Data has been stratified here due to severe class imbalance.\n",
    "\n",
    "data = pd.read_csv('dft_comb_new.csv')\n",
    "labeled_data = data[data['injury_report'] != 'x']\n",
    "\n",
    "Xtr, Xte, Ytr, Yte =  model_selection.train_test_split(labeled_data['tweet'],\n",
    "                                                       labeled_data['injury_report'].astype(int),\n",
    "                                                       stratify=labeled_data['injury_report'],\n",
    "                                                       test_size=0.3)\n",
    "\n",
    "v = TfidfVectorizer()\n",
    "v.fit(data['tweet'].dropna())\n",
    "\n",
    "Xtr_tfidf = v.transform(Xtr)\n",
    "Xte_tfidf = v.transform(Xte)\n",
    "\n",
    "v = CountVectorizer(binary=True)\n",
    "\n",
    "v.fit(data['tweet'].dropna())\n",
    "Xtr_bool = v.transform(Xtr)\n",
    "Xte_bool = v.transform(Xte)\n",
    "\n",
    "v = CountVectorizer()\n",
    "\n",
    "v.fit(data['tweet'].dropna())\n",
    "Xtr_count = v.transform(Xtr)\n",
    "Xte_count = v.transform(Xte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 8 folds for each of 19 candidates, totalling 152 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  35 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=3)]: Done 152 out of 152 | elapsed:   18.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4060   92]\n",
      " [ 103  329]]\n",
      "KNeighborsClassifier(n_neighbors=1, weights='distance')\n"
     ]
    }
   ],
   "source": [
    "# K Nearest Neighbors over TF-IDF representation\n",
    "\n",
    "kNN = KNeighborsClassifier()\n",
    "param_search = [{'weights': ['distance'], 'n_neighbors': [i for i in range(1,20)]}]\n",
    "\n",
    "grid_search = GridSearchCV(kNN, param_search, cv=8, scoring='recall', n_jobs=3, verbose=2)\n",
    "grid_search.fit(Xtr_tfidf, Ytr)\n",
    "\n",
    "y_hat = grid_search.best_estimator_.predict(Xte_tfidf)\n",
    "\n",
    "print(confusion_matrix(Yte, y_hat))\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 8 folds for each of 10000 candidates, totalling 80000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done 266 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=3)]: Done 3258 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=3)]: Done 9754 tasks      | elapsed:   21.5s\n",
      "[Parallel(n_jobs=3)]: Done 18810 tasks      | elapsed:   41.8s\n",
      "[Parallel(n_jobs=3)]: Done 30490 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 44730 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 61594 tasks      | elapsed:  2.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3972  180]\n",
      " [  43  389]]\n",
      "BernoulliNB(alpha=0.05300530053005301)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done 79995 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=3)]: Done 80000 out of 80000 | elapsed:  2.9min finished\n"
     ]
    }
   ],
   "source": [
    "# Bernoulli Naive Bayes; must be done over Boolean Representaion\n",
    "\n",
    "BNB = BernoulliNB()\n",
    "\n",
    "param_search = [{'alpha': list(np.linspace(0, 0.5, 10000))}]\n",
    "\n",
    "grid_search = GridSearchCV(BNB, param_search, cv=8, scoring='recall', n_jobs=3, verbose=2)\n",
    "grid_search.fit(Xtr_bool, Ytr)\n",
    "\n",
    "y_hat = grid_search.best_estimator_.predict(Xte_bool)\n",
    "\n",
    "print(confusion_matrix(Yte, y_hat))\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 8 folds for each of 10000 candidates, totalling 80000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done 346 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=3)]: Done 4218 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=3)]: Done 10714 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=3)]: Done 19770 tasks      | elapsed:   32.0s\n",
      "[Parallel(n_jobs=3)]: Done 31450 tasks      | elapsed:   50.3s\n",
      "[Parallel(n_jobs=3)]: Done 45690 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=3)]: Done 62554 tasks      | elapsed:  1.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3896  256]\n",
      " [  34  398]]\n",
      "MultinomialNB(alpha=0.13551355135513551)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done 80000 out of 80000 | elapsed:  2.2min finished\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes; must be done over Count Representation\n",
    "\n",
    "MNB = MultinomialNB()\n",
    "\n",
    "param_search = [{'alpha': list(np.linspace(0, 0.5, 10000))}]\n",
    "\n",
    "grid_search = GridSearchCV(MNB, param_search, cv=8, scoring='recall', n_jobs=3, verbose=2)\n",
    "grid_search.fit(Xtr_count, Ytr)\n",
    "\n",
    "y_hat = grid_search.best_estimator_.predict(Xte_count)\n",
    "\n",
    "print(confusion_matrix(Yte, y_hat))\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 8 folds for each of 42 candidates, totalling 336 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done 110 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=3)]: Done 252 tasks      | elapsed:   48.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3997  155]\n",
      " [  47  385]]\n",
      "LogisticRegression(C=1, class_weight='balanced', solver='liblinear')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done 336 out of 336 | elapsed:  1.0min finished\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression over TF-IDF Representation\n",
    "\n",
    "LReg = LogisticRegression()\n",
    "\n",
    "param_search = [{'penalty': ['l1', 'l2'],\n",
    "                'C': [2 ** i for i in range(-5, 16)],\n",
    "                'class_weight': ['balanced'],\n",
    "                'solver': ['liblinear']}]\n",
    "\n",
    "grid_search = GridSearchCV(LReg, param_search, cv=8, scoring='recall', n_jobs=3, verbose=2)\n",
    "grid_search.fit(Xtr_tfidf, Ytr)\n",
    "\n",
    "y_hat = grid_search.best_estimator_.predict(Xte_tfidf)\n",
    "\n",
    "print(confusion_matrix(Yte, y_hat))\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 8 folds for each of 84 candidates, totalling 672 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  35 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=3)]: Done 156 tasks      | elapsed: 19.2min\n",
      "[Parallel(n_jobs=3)]: Done 359 tasks      | elapsed: 44.1min\n",
      "[Parallel(n_jobs=3)]: Done 642 tasks      | elapsed: 82.7min\n",
      "[Parallel(n_jobs=3)]: Done 672 out of 672 | elapsed: 87.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3929  223]\n",
      " [  68  364]]\n",
      "RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
      "                       max_depth=39, min_samples_leaf=5, min_samples_split=5,\n",
      "                       n_estimators=1000)\n"
     ]
    }
   ],
   "source": [
    "# Random Forest over Boolean Representation\n",
    "\n",
    "Forest = RandomForestClassifier()\n",
    "\n",
    "\n",
    "param_search = [{'criterion': ['entropy', 'gini'], 'min_samples_split': [5], \n",
    "                 'max_depth': [i for i in range(20, 41)],\n",
    "                'min_samples_leaf': [5],\n",
    "                'n_estimators': [1000],\n",
    "                'class_weight': ['balanced', 'balanced_subsample']}]\n",
    "\n",
    "grid_search = GridSearchCV(Forest, param_search, cv=8, scoring='recall', n_jobs=3, verbose=2)\n",
    "grid_search.fit(Xtr_bool, Ytr)\n",
    "\n",
    "y_hat = grid_search.best_estimator_.predict(Xte_bool)\n",
    "\n",
    "print(confusion_matrix(Yte, y_hat))\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 8 folds for each of 84 candidates, totalling 672 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  35 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=3)]: Done 156 tasks      | elapsed: 19.6min\n",
      "[Parallel(n_jobs=3)]: Done 359 tasks      | elapsed: 45.6min\n",
      "[Parallel(n_jobs=3)]: Done 642 tasks      | elapsed: 84.9min\n",
      "[Parallel(n_jobs=3)]: Done 672 out of 672 | elapsed: 90.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3939  213]\n",
      " [  72  360]]\n",
      "RandomForestClassifier(class_weight='balanced', max_depth=40,\n",
      "                       min_samples_leaf=5, min_samples_split=5,\n",
      "                       n_estimators=1000)\n"
     ]
    }
   ],
   "source": [
    "# Random Forest over TF-IDF Representation\n",
    "\n",
    "Forest = RandomForestClassifier()\n",
    "\n",
    "\n",
    "param_search = [{'criterion': ['entropy', 'gini'], 'min_samples_split': [5], \n",
    "                 'max_depth': [i for i in range(20, 41)],\n",
    "                'min_samples_leaf': [5],\n",
    "                'n_estimators': [1000],\n",
    "                'class_weight': ['balanced', 'balanced_subsample']}]\n",
    "\n",
    "grid_search = GridSearchCV(Forest, param_search, cv=8, scoring='recall', n_jobs=3, verbose=2)\n",
    "grid_search.fit(Xtr_tfidf, Ytr)\n",
    "\n",
    "y_hat = grid_search.best_estimator_.predict(Xte_tfidf)\n",
    "\n",
    "print(confusion_matrix(Yte, y_hat))\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4092   60]\n",
      " [  87  345]]\n",
      "SVC(C=8, kernel='linear')\n"
     ]
    }
   ],
   "source": [
    "# SVM; must be done over TF-IDF Representation\n",
    "\n",
    "SVM = svm.SVC()\n",
    "\n",
    "search_area = [\n",
    "  {'C': [2 ** i for i in list(range(-5,16))], 'kernel': ['linear']},\n",
    "  {'C': [2 ** i for i in list(range(-5,16))], 'gamma': [2 ** i for i in list(range(-15,4))], 'kernel': ['rbf']},\n",
    " ]\n",
    "\n",
    "grid_search = GridSearchCV(SVM, search_area, cv=8, scoring='recall', n_jobs=3)\n",
    "grid_search.fit(Xtr_tfidf, Ytr)\n",
    "\n",
    "y_hat = grid_search.best_estimator_.predict(Xte_tfidf)\n",
    "\n",
    "print(confusion_matrix(Yte, y_hat))\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
