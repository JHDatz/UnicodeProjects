{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import model_selection, svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['count.joblib']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly partition the data and convert it to Count, Boolean, and TF-IDF Formats.\n",
    "# PCA has been removed due to its rather intense computational constraints. :(\n",
    "# Data has been stratified here due to severe class imbalance.\n",
    "\n",
    "#data = pd.read_csv('filtered.csv')\n",
    "data = pd.read_csv('clean.csv')\n",
    "labeled_data = data[data['injury_report'] != 'x']\n",
    "\n",
    "Xtr, Xte, Ytr, Yte =  model_selection.train_test_split(labeled_data['tweet'],\n",
    "                                                       labeled_data['injury_report'].astype(int),\n",
    "                                                       stratify=labeled_data['injury_report'],\n",
    "                                                       test_size=0.3)\n",
    "\n",
    "v = TfidfVectorizer()\n",
    "v.fit(data['tweet'].dropna())\n",
    "\n",
    "Xtr_tfidf = v.transform(Xtr)\n",
    "Xte_tfidf = v.transform(Xte)\n",
    "\n",
    "dump(v, 'tfidf.joblib')\n",
    "\n",
    "v = CountVectorizer(binary=True)\n",
    "\n",
    "v.fit(data['tweet'].dropna())\n",
    "Xtr_bool = v.transform(Xtr)\n",
    "Xte_bool = v.transform(Xte)\n",
    "\n",
    "dump(v, 'bool.joblib')\n",
    "\n",
    "v = CountVectorizer()\n",
    "\n",
    "v.fit(data['tweet'].dropna())\n",
    "Xtr_count = v.transform(Xtr)\n",
    "Xte_count = v.transform(Xte)\n",
    "\n",
    "dump(v, 'count.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 8 folds for each of 19 candidates, totalling 152 fits\n",
      "[[5678   14]\n",
      " [ 420  118]]\n",
      "KNeighborsClassifier(n_neighbors=1, weights='distance')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['kNN.joblib']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K Nearest Neighbors over TF-IDF representation\n",
    "\n",
    "kNN = KNeighborsClassifier()\n",
    "param_search = [{'weights': ['distance'], 'n_neighbors': [i for i in range(1,20)]}]\n",
    "\n",
    "grid_search = GridSearchCV(kNN, param_search, cv=8, scoring='recall', n_jobs=2, verbose=2)\n",
    "grid_search.fit(Xtr_tfidf, Ytr)\n",
    "\n",
    "y_hat = grid_search.best_estimator_.predict(Xte_tfidf)\n",
    "\n",
    "print(confusion_matrix(Yte, y_hat))\n",
    "print(grid_search.best_estimator_)\n",
    "dump(grid_search.best_estimator_, 'kNN.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 8 folds for each of 10000 candidates, totalling 80000 fits\n",
      "[[5446  246]\n",
      " [  71  467]]\n",
      "BernoulliNB(alpha=0.05394539453945395)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['bernoulliNB.joblib']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bernoulli Naive Bayes; must be done over Boolean Representaion\n",
    "\n",
    "BNB = BernoulliNB()\n",
    "\n",
    "param_search = [{'alpha': list(np.linspace(0, 0.1, 10000))}]\n",
    "\n",
    "grid_search = GridSearchCV(BNB, param_search, cv=8, scoring='recall', n_jobs=2, verbose=2)\n",
    "grid_search.fit(Xtr_bool, Ytr)\n",
    "\n",
    "y_hat = grid_search.best_estimator_.predict(Xte_bool)\n",
    "\n",
    "print(confusion_matrix(Yte, y_hat))\n",
    "print(grid_search.best_estimator_)\n",
    "dump(grid_search.best_estimator_, 'bernoulliNB.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 8 folds for each of 10000 candidates, totalling 80000 fits\n",
      "[[5356  336]\n",
      " [  78  460]]\n",
      "MultinomialNB(alpha=0.0626062606260626)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['multinomialNB.joblib']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multinomial Naive Bayes; must be done over Count Representation\n",
    "\n",
    "MNB = MultinomialNB()\n",
    "\n",
    "param_search = [{'alpha': list(np.linspace(0, 0.1, 10000))}]\n",
    "\n",
    "grid_search = GridSearchCV(MNB, param_search, cv=8, scoring='recall', n_jobs=2, verbose=2)\n",
    "grid_search.fit(Xtr_count, Ytr)\n",
    "\n",
    "y_hat = grid_search.best_estimator_.predict(Xte_count)\n",
    "\n",
    "print(confusion_matrix(Yte, y_hat))\n",
    "print(grid_search.best_estimator_)\n",
    "dump(grid_search.best_estimator_, 'multinomialNB.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 8 folds for each of 42 candidates, totalling 336 fits\n",
      "[[5576  116]\n",
      " [  54  484]]\n",
      "LogisticRegression(C=1, class_weight='balanced', penalty='l1',\n",
      "                   solver='liblinear')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['logistic_regression.joblib']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression over TF-IDF Representation\n",
    "\n",
    "LReg = LogisticRegression()\n",
    "\n",
    "param_search = [{'penalty': ['l1', 'l2'],\n",
    "                'C': [2 ** i for i in range(-5, 16)],\n",
    "                'class_weight': ['balanced'],\n",
    "                'solver': ['liblinear']}]\n",
    "\n",
    "grid_search = GridSearchCV(LReg, param_search, cv=8, scoring='recall', n_jobs=2, verbose=2)\n",
    "grid_search.fit(Xtr_tfidf, Ytr)\n",
    "\n",
    "y_hat = grid_search.best_estimator_.predict(Xte_tfidf)\n",
    "\n",
    "print(confusion_matrix(Yte, y_hat))\n",
    "print(grid_search.best_estimator_)\n",
    "dump(grid_search.best_estimator_, 'logistic_regression.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 8 folds for each of 84 candidates, totalling 672 fits\n",
      "[[5384   93]\n",
      " [ 181  351]]\n",
      "RandomForestClassifier(class_weight='balanced', max_depth=21)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['random_forest_bool.joblib']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest over Boolean Representation\n",
    "\n",
    "Forest = RandomForestClassifier()\n",
    "\n",
    "\n",
    "param_search = [{'criterion': ['entropy', 'gini'],\n",
    "                 'max_depth': [i for i in range(20, 41)],\n",
    "                'n_estimators': [100],\n",
    "                'class_weight': ['balanced', 'balanced_subsample']}]\n",
    "\n",
    "grid_search = GridSearchCV(Forest, param_search, cv=8, scoring='recall', n_jobs=2, verbose=2)\n",
    "grid_search.fit(Xtr_bool, Ytr)\n",
    "\n",
    "y_hat = grid_search.best_estimator_.predict(Xte_bool)\n",
    "\n",
    "print(confusion_matrix(Yte, y_hat))\n",
    "print(grid_search.best_estimator_)\n",
    "dump(grid_search.best_estimator_, 'random_forest_bool.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 8 folds for each of 84 candidates, totalling 672 fits\n",
      "[[5282  195]\n",
      " [ 112  420]]\n",
      "RandomForestClassifier(class_weight='balanced_subsample', criterion='entropy',\n",
      "                       max_depth=38, min_samples_leaf=5, min_samples_split=5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['random_forest_tfidf.joblib']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest over TF-IDF Representation\n",
    "\n",
    "Forest = RandomForestClassifier()\n",
    "\n",
    "\n",
    "param_search = [{'criterion': ['entropy', 'gini'], 'min_samples_split': [5], \n",
    "                 'max_depth': [i for i in range(20, 41)],\n",
    "                'min_samples_leaf': [5],\n",
    "                'n_estimators': [100],\n",
    "                'class_weight': ['balanced', 'balanced_subsample']}]\n",
    "\n",
    "grid_search = GridSearchCV(Forest, param_search, cv=8, scoring='recall', n_jobs=2, verbose=2)\n",
    "grid_search.fit(Xtr_tfidf, Ytr)\n",
    "\n",
    "y_hat = grid_search.best_estimator_.predict(Xte_tfidf)\n",
    "\n",
    "print(confusion_matrix(Yte, y_hat))\n",
    "print(grid_search.best_estimator_)\n",
    "dump(grid_search.best_estimator_, 'random_forest_tfidf.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 8 folds for each of 21 candidates, totalling 168 fits\n",
      "[[5661   31]\n",
      " [ 104  434]]\n",
      "SVC(C=4, kernel='linear')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['svm.joblib']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM; must be done over TF-IDF Representation\n",
    "\n",
    "SVM = svm.SVC()\n",
    "\n",
    "search_area = [\n",
    "  {'C': [2 ** i for i in list(range(-5,16))], 'kernel': ['linear']},\n",
    "  #{'C': [2 ** i for i in list(range(-5,16))], 'gamma': [2 ** i for i in list(range(-15,4))], 'kernel': ['rbf']},\n",
    "  # Removed because it was computationally expensive and seemed to provide no advantage.\n",
    "  # Perhaps that would change with more data / more word lemmatization.\n",
    " ]\n",
    "\n",
    "grid_search = GridSearchCV(SVM, search_area, cv=8, scoring='recall', n_jobs=2, verbose=2)\n",
    "grid_search.fit(Xtr_tfidf, Ytr)\n",
    "\n",
    "y_hat = grid_search.best_estimator_.predict(Xte_tfidf)\n",
    "\n",
    "print(confusion_matrix(Yte, y_hat))\n",
    "print(grid_search.best_estimator_)\n",
    "dump(grid_search.best_estimator_, 'svm.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
